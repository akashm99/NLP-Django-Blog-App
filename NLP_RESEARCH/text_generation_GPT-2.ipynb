{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f433dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.61.1-py2.py3-none-any.whl (75 kB)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-win_amd64.whl (213 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.7.1-cp38-cp38-win_amd64.whl (270 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from transformers) (21.0)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.21.0-cp38-cp38-win_amd64.whl (14.0 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: click in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\akash\\anaconda3\\envs\\nlp_flask_blog\\lib\\site-packages (from click->sacremoses->transformers) (0.4.4)\n",
      "Installing collected packages: urllib3, idna, chardet, typing-extensions, tqdm, requests, regex, joblib, filelock, tokenizers, sacremoses, pyyaml, numpy, huggingface-hub, transformers\n",
      "Successfully installed chardet-4.0.0 filelock-3.0.12 huggingface-hub-0.0.12 idna-2.10 joblib-1.0.1 numpy-1.21.0 pyyaml-5.4.1 regex-2021.7.1 requests-2.25.1 sacremoses-0.0.45 tokenizers-0.10.3 tqdm-4.61.1 transformers-4.8.2 typing-extensions-3.10.0.0 urllib3-1.26.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a4a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.4.1\n",
    "# !pip install tensorflow-gpu==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521d003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c548cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b19ad4a8494422b50b8e6857032fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/764 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a73f042dd84393a2d8e4db510129be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da464ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d0af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'GPT is the future'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5717b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23e27aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   38, 11571,   318,   262,  2003]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d18c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length=500, min_length=100 , num_beams=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "074ce1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   38, 11571,   318,   262,  2003,   286, 14492,    11,   290,   340,\n",
       "           338,   994,   284,  2652,    13,   198,   198,  1212,  2708,   373,\n",
       "          6198,  3199,   319,   383, 42427,    13,  4149,   262,  2656,  2708,\n",
       "            13,  7281,  1439,   388, 47390, 49573,  2488, 31199, 14012, 14573,\n",
       "           319,  3009,    13, 15069,  1584, 20249,  3000,  7311,    11,  3457,\n",
       "            13,  1439,  2489, 10395,    13,   770,  2587,   743,   407,   307,\n",
       "          3199,    11,  7025,    11, 30101,    11,   393, 38913,    13, 14365,\n",
       "           517,   546,   674, 16777,  7820,   290, 17637,   286,  5765,    13,\n",
       "         19808,   284, 27731,    45,    25,  2638,  1378,  2503,    13,    66,\n",
       "            73,    77,    13,   785,    14, 23065,  2229,    14,  9630,    13,\n",
       "          6494, 50256]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22593f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT is the future of computing, and it's here to stay.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow Allum Bokhari @LibertarianBlue on Twitter. Copyright 2016 Cable News Network, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed. Learn more about our Privacy Policy and Terms of Use. Subscribe to CJN: http://www.cjn.com/programming/index.html\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb365e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
